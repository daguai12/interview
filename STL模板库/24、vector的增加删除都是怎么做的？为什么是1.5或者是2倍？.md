### 1\. `vector` 的增加与删除操作

`std::vector` 的所有行为都源于其核心特性：它必须在内存中维持一块**连续的存储空间**。

#### a) 增加元素 (`push_back` 和 `insert`)

1.  **当容量足够时 ( `size() < capacity()` )**

      * **`push_back(value)`**：这是最高效的增加方式。直接在 `size()` 的末尾位置构造新元素，然后将 `size()` 的计数值加一。时间复杂度为 **O(1)**。
      * **`insert(iterator, value)`**：在迭代器指向的位置插入元素。为了保持内存的连续性，从插入点开始到末尾的**所有元素都必须向后“平移”一位**。这是一个昂贵的操作，时间复杂度为 **O(n)**。

2.  **当容量不足时 ( `size() == capacity()` )**
    这是 `vector` 最关键的“动态”特性——**扩容 (Reallocation)**。

      * **过程**：
        1.  申请一块**全新的、更大的**连续内存空间。
        2.  将旧内存中的**所有元素**拷贝或移动到新内存中。
        3.  **释放**旧的内存空间。
        4.  在新内存的末尾构造要插入的新元素。
      * **迭代器失效**：这个过程是“毁灭性”的。因为旧的内存被完全释放，所以**所有**指向原 `vector` 元素的**迭代器、指针和引用都会立即失效**。

#### b) 删除元素 (`pop_back` 和 `erase`)

1.  **`pop_back()`**：

      * 删除最后一个元素。只需调用该元素的析构函数，并将 `size()` 减一。
      * **不会释放内存**，`capacity()` 保持不变。
      * 时间复杂度为 **O(1)**。

2.  **`erase(iterator)`**：

      * 删除迭代器指向的元素。
      * 调用该元素的析构函数。
      * 为了填补空缺，**将该位置之后的所有元素向前“平移”一位**。
      * 时间复杂度为 **O(n)**。
      * **迭代器失效**：由于元素移动，**所有指向被删除元素以及其后所有元素**的迭代器都会**失效**。

#### c) `remove` 算法 vs. `erase` 成员函数

您的第六点总结非常到位，这是一个常见的混淆点。

  * **`std::remove`**：是一个STL**算法**，它**不改变容器的大小**。它做的是“**整理**”：将所有**不等于**指定值的元素移动到容器的前端，并返回一个指向“新的逻辑末尾”的迭代器。容器尾部的元素处于一种“有效但未指定”的状态。
  * **Erase-Remove Idiom**：要真正从 `vector` 中删除这些元素，必须结合 `erase` 来使用：
    ```cpp
    #include <algorithm>
    // 1. remove 将所有不等于5的元素移动到前面，并返回 new_end
    auto new_end = std::remove(vec.begin(), vec.end(), 5);
    // 2. erase 从 new_end 到物理末尾，删除所有“垃圾”元素
    vec.erase(new_end, vec.end());
    ```

-----

### 2\. 为什么扩容因子是 1.5 或 2 倍？

您的分析非常深刻，这确实是**时间与空间**的经典权衡。

**核心目标**：让 `push_back` 的\*\*摊销时间复杂度（Amortized Time Complexity）\*\*达到 **O(1)**。

  * **如果采用“增加固定大小”的策略**（例如每次扩容都 `+100` 个元素），那么随着 `vector` 越来越大，扩容会越来越频繁。综合来看，将N个元素插入 `vector` 的总时间复杂度将是 O(N²)，平均每次 `push_back` 的复杂度是 O(N)。这无法接受。

  * **如果采用“乘以一个因子”的策略**（`capacity = capacity * k`），可以证明，将N个元素插入 `vector` 的总时间复杂度为 O(N)，因此平摊到每次 `push_back` 的复杂度就是 **O(1)**。

#### 1.5 倍 vs. 2 倍的选择

  * **2 倍 (GCC 等)**：

      * **优点**：计算简单（可以通过位移运算实现），扩容次数相对较少，时间效率的摊销表现更好。
      * **缺点**：正如您所分析的，这种策略在内存管理上可能不友好。因为新申请的内存 `2n` 总是大于之前所有已分配内存的总和 (`n + n/2 + n/4 + ... < 2n`)。这意味着，内存分配器**无法复用**刚刚被 `vector` 释放掉的那些较小的内存块，可能导致**内存碎片化**程度更高。

  * **1.5 倍 (Visual Studio 等)**：

      * **优点**：一种更“温和”的增长策略。它在**空间利用率**上表现更好，浪费的内存相对较少。同时，它使得内存分配器更有可能在之前释放的内存碎片中找到合适的位置，从而**复用内存**。
      * **缺点**：扩容可能会比2倍增长更频繁一些，数学计算也比 `*2` 稍复杂。

**结论**：选择1.5倍还是2倍，是不同标准库实现者在**摊销时间效率**和**内存空间利用率**之间做出的不同权衡。没有绝对的优劣，1.5倍被认为是一个更均衡的选择。