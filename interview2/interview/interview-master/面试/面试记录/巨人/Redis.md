

### **一、[redis]怎么做持久化呀？**

Redis 的持久化主要有两大机制，即 AOF（Append Only File）日志和 RDB 快照。

#### AOF

AOF 日志是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志，如下图所示：

![img](https://static001.geekbang.org/resource/image/40/1f/407f2686083afc37351cfd9107319a1f.jpg)

传统数据库的日志，例如 redo log（重做日志），记录的是修改后的数据，而 AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。



为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。除此之外，AOF 还有一个好处：它是在命令执行后才记录日志，所以**不会阻塞当前的写操作**。

##### 三种写回策略

AOF 配置项 appendfsync 的三个可选值。

* ![img](https://static001.geekbang.org/resource/image/72/f8/72f547f18dbac788c7d11yy167d7ebf8.jpg)


##### 日志文件太大了怎么办？

AOF 重写机制，和 AOF 日志由主线程写回不同，重写过程是由后台子进程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。我把重写的过程总结为“**一个拷贝，两处日志**”。

![img](https://static001.geekbang.org/resource/image/6b/e8/6b054eb1aed0734bd81ddab9a31d0be8.jpg)

使用两个日志保证在重写过程中，新写入的数据不会丢失。



#### RDB

Redis 的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是**全量快照**。

Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。

* save：在主线程中执行，会导致阻塞；
* bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。

![img](https://static001.geekbang.org/resource/image/a2/58/a2e5a3571e200cb771ed8a1cd14d5558.jpg)

​					写时复制技术（Copy-On-Write, COW）

这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响。



Redis 4.0 中提出了一个**混合使用 AOF 日志和内存快照的方法**。









### 二、**分布式锁怎么设计呀？**

在应对并发问题时，除了原子操作，Redis 客户端还可以通过加锁的方式，来控制并发写操作对共享数据的修改，从而保证数据的正确性。

但是，Redis 属于分布式系统，当有多个客户端需要争抢锁时，我们必须要保证，**这把锁不能是某个客户端本地的锁**。

Redis 本身可以被多个客户端共享访问，正好就是一个共享存储系统，可以用来保存分布式锁。而且 Redis 的读写性能高，可以应对高并发的锁操作场景。

#### 1.基于单个 Redis 节点的实现



<img src="https://static001.geekbang.org/resource/image/1d/45/1d18742c1e5fc88835ec27f1becfc145.jpg?wh=2820*2250" alt="img" style="zoom:33%;" />

<img src="https://static001.geekbang.org/resource/image/c7/82/c7c413b47d42f06f08fce92404f31e82.jpg?wh=3000*2250" alt="img" style="zoom: 33%;" />

因为加锁包含了三个操作（读取锁变量、判断锁变量值以及把锁变量值设置为 1），而这三个操作在执行时需要保证原子性。那怎么保证原子性呢？

要想保证操作的原子性，有两种通用的方法，分别是使用 Redis 的单命令操作和使用 Lua 脚本(略)。

##### 单命令操作

单命令操作: 首先是 SETNX 命令，它用于设置键值对的值。具体来说，就是这个命令在执行时会判断键值对是否存在，如果不存在，就设置键值对的值，如果存在，就不做任何设置。

使用 DEL 命令删除锁变量。

```c
// 加锁
SETNX lock_key 1
// 业务逻辑
DO THINGS
// 释放锁
DEL lock_key
```



使用 SETNX 和 DEL 命令组合实现分布锁，存在两个潜在的风险。

1. 假如某个客户端在执行了 SETNX 命令、加锁之后，紧接着却在操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。

一个有效的解决方法是，**给锁变量设置一个过期时间**。



2. 如果客户端 A 执行了 SETNX 命令加锁后，假设客户端 B 执行了 DEL 命令释放锁，此时，客户端 A 的锁就被误释放了。

**需要能区分来自不同客户端的锁操作**(用SET替换SETNX)

Redis 给 SET 命令提供了类似的选项 NX，用来实现“不存在即设置”。如果使用了 NX 选项，SET 命令只有在键值对不存在时，才会进行设置，否则不做赋值操作。此外，SET 命令在执行时还可以带上 EX 或 PX 选项，用来设置键值对的过期时间。

```c
// 加锁, unique_value作为客户端唯一性的标识
SET lock_key unique_value NX PX 10000
```



#### 2. 基于多个 Redis 节点实现高可靠的分布式锁

为了避免 Redis 实例故障而导致的锁无法工作的问题，Redis 的开发者提出了分布式锁算法 Redlock。

Redlock 算法的基本思路，是让客户端和多个独立的 Redis 实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作（并且客户端获取锁的总耗时没有超过锁的有效时间），那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败。这样一来，即使有单个 Redis 实例发生故障，因为锁变量在其它实例上也有保存，所以，客户端仍然可以正常地进行锁操作，锁变量并不会丢失。









### 三、**怎样把不常用的数据从缓存里淘汰掉呀？**

数据淘汰机制包括两步：

第一，根据一定的策略，筛选出对应用访问来说“不重要”的数据；

第二，将这些数据从缓存中删除，为新来的数据腾出空间，

![img](https://static001.geekbang.org/resource/image/04/f6/04bdd13b760016ec3b30f4b02e133df6.jpg)



不过，LRU 算法在实际实现时，需要用链表管理所有的缓存数据，这会**带来额外的空间开销**。而且，当有数据被访问时，需要在链表上把该数据移动到 MRU 端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。

所以，在 Redis 中，LRU 算法被做了简化，以减轻数据淘汰对缓存性能的影响。具体来说，Redis 默认会记录每个数据的最近一次访问的时间戳（由键值对数据结构 RedisObject 中的 lru 字段记录）。然后，Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。

当需要再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。这儿的挑选标准是：**能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值**。

#### 如何处理被淘汰的数据？

干净数据和脏数据的区别就在于，和最初从后端数据库里读取时的值相比，有没有被修改过。

![img](https://static001.geekbang.org/resource/image/95/5e/953e48912yy9515abf9db588d447cc5e.jpg)



### **四、不同的[redis]节点怎么做同步呀？**

我们一起学习了 Redis 的主从库同步的基本原理，总结来说，有三种模式：

* 全量复制、

* 基于长连接的命令传播，

* 增量复制。

Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。

* 读操作：主库、从库都可以接收；
* 写操作：首先到主库执行，然后，主库将写操作同步给从库。



![img](https://static001.geekbang.org/resource/image/80/2f/809d6707404731f7e493b832aa573a2f.jpg)





![img](https://static001.geekbang.org/resource/image/63/a1/63d18fd41efc9635e7e9105ce1c33da1.jpg)



长连接复制是主从库正常运行后的常规同步阶段。在这个阶段中，主从库之间通过命令传播实现同步。不过，这期间如果遇到了网络断连，增量复制就派上用场了。



“主 - 从 - 从”这一级联模式，来缓解主库的压力。



### **五、[redis]怎么负载均衡**

切片集群中，数据会按照一定的分布规则分散到不同的实例上保存。

* **数据量倾斜**：在某些情况下，实例上的数据分布不均衡，某个实例上的数据特别多。
* **数据访问倾斜**：虽然每个集群实例上的数据量相差不大，但是某个实例上的数据是热点数据，被访问得非常频繁。

#### 数据量倾斜

#### 1. bigkey 导致倾斜

某个实例上正好保存了 bigkey。bigkey 的 value 值很大（String 类型），或者是 bigkey 保存了大量集合元素（集合类型），会导致这个实例的数据量增加，内存资源消耗也相应增加。

一个根本的应对方法是，**我们在业务层生成数据时，要尽量避免把过多的数据保存在同一个键值对中。**

此外，**如果 bigkey 正好是集合类型，我们还有一个方法，就是把 bigkey 拆分成很多个小的集合类型数据，分散保存在不同的实例上。**

#### 2. Slot 分配不均衡导致倾斜

迁移命令把这些 Slot 迁移到其它实例上

#### 3. Hash Tag 导致倾斜

如果使用 Hash Tag 进行切片的数据会带来较大的访问压力，就优先考虑避免数据倾斜，最好不要使用 Hash Tag 进行数据切片。

#### 数据访问倾斜的成因和应对方法

通常来说，热点数据以服务读操作为主，在这种情况下，我们可以采用**热点数据**多副本的方法来应对。
