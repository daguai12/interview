#### 1. HTTP 未使用长连接（Keep-Alive）
如果客户端或服务端任意一方禁用了 HTTP Keep-Alive（例如请求头中包含 `Connection: close`），那么在每次 HTTP 请求响应后，连接就会被关闭。根据主流 Web 服务器的设计，通常会由**服务端来主动关闭**，从而导致服务端产生 TIME_WAIT 状态。

#### 2. HTTP 长连接空闲超时
为了避免资源浪费，服务器（如 Nginx）会配置一个 `keepalive_timeout`。如果一个客户端在建立长连接后，在超时时间内没有任何新的请求，**服务器会主动关闭这个空闲连接**以回收资源。在高并发下，大量此类连接超时就会产生大量 TIME_WAIT。

#### 3. HTTP 长连接处理请求数达到上限
服务器通常也会配置一条长连接上能处理的最大请求数，比如 Nginx 的 `keepalive_requests`（默认 100）。当一个连接处理的请求数达到这个上限后，**服务器同样会主动关闭该连接**。在 QPS 非常高的场景下，这个默认值可能很快被触及，导致服务器频繁地关闭连接，从而产生大量 TIME_WAIT。

**总结一下**，这三种情况本质上都是服务器的一种自我保护和资源管理机制。在高并发场景下，这些正常的机制就可能导致 TIME_WAIT 状态的连接数量激增，这时就需要我们去排查并调整相应的配置参数（如开启 Keep-Alive、调整超时时间或请求数上限）。



好的，这两个问题都指向一个核心结论：**在 HTTP 短连接中，无论哪一方提出关闭，最终执行主动关闭操作的几乎总是服务端。**

下面我为您分别解释这两个场景：

---

### 问题一：客户端禁用 Keep-Alive，服务端开启

* **场景**: 客户端发起请求，并在请求头中明确加入 `Connection: close`。
* **谁主动关闭**: **服务端**。

**为什么这么设计？**

这可以理解为一种**“指令与执行”**的关系。

1.  **客户端下达指令**: 客户端通过 `Connection: close` 明确告诉服务端：“我这次请求完事后，就不再使用这个连接了，请关闭它。”
2.  **服务端执行指令**: 服务端接收到这个指令。它首先完成自己的本职工作——处理请求并发送完整的 HTTP 响应。当响应发送完毕时，这个 HTTP 事务的生命周期就结束了。
3.  **最佳关闭时机**: 此时，服务端处于整个流程的**末端**，它最清楚什么时候“工作已完成”。因此，由它来执行客户端的“关闭”指令，是最合理、最自然的选择。

简单来说，客户端是决策者，服务端是执行者。服务端在完成响应后，遵循客户端的意愿，主动关闭了连接。

---

### 问题二：客户端开启 Keep-Alive，服务端禁用

* **场景**: 客户端希望复用连接（没有 `Connection: close`），但服务端配置为不支持长连接，所以在响应头中加入了 `Connection: close`。
* **谁主动关闭**: **服务端**。

**为什么这么设计？**

这主要是出于**“服务器效率”**的考虑。

服务器的目标是尽快处理完请求，释放资源去服务其他客户端。我们来对比一下两种关闭方式的成本：

1.  **让服务端主动关闭（当前实现）**:
    * 服务端发送完响应数据。
    * 立即调用一次 `close()` 系统调用。
    * 任务完成！服务器进程可以立刻将这个连接抛之脑后，剩下的四次挥手全部由操作系统内核处理。这个过程非常高效，只有一次系统调用。

2.  **让客户端主动关闭（一种假设）**:
    * 服务端发送完响应数据。
    * 此时，它不能直接丢弃连接，必须**等待**客户端先关闭。
    * 这意味着服务端需要继续监听这个 Socket，等待客户端发来 FIN 包（表现为 Socket 变为可读）。
    * 当监听到事件后，服务端还需要调用一次 `read()` 来确认是对方关闭了连接。
    * 最后，服务端再调用 `close()`。
    * 这个过程不仅需要**多次系统调用**，还**延长了 Socket 的生命周期**，占用了服务器的资源。

**结论**：为了效率和简单性，即使是服务端决定不再保持连接，它也会选择自己主动关闭，而不是把关闭的“皮球”踢给客户端，然后傻傻地等待。

---

### 总结

无论哪种情况，只要连接最终没有被保持（Keep-Alive），主流的 Web 服务器都会选择在**发送完响应后立即主动关闭连接**。这个设计决策是导致服务器上容易出现大量 `TIME_WAIT` 状态的直接原因。